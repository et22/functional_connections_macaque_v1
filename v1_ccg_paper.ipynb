{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c8d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.io import loadmat\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from ipywidgets import interact, interactive, interactive_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import scipy\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import chi2_contingency, ttest_ind,ttest_1samp, spearmanr\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "from random import randint\n",
    "#import networkx as nx\n",
    "#from pyvis.network import Network\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad8fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config\n",
    "class structtype():\n",
    "    pass\n",
    "\n",
    "config = structtype()\n",
    "config.deploy_flag = 0\n",
    "config.figure_dir = \"figures/python/\"\n",
    "config.session_4c56_boundaries = [1070, 1190,990,750,550]\n",
    "def set_axis_defaults():\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "# define cat variable labels\n",
    "labels = {'cl': [\"2/3\", \"4a/b\", \"4cα\", \"4cβ\", \"5\", \"6\", \"WM\"], \n",
    "         'sc': [\"Com.\", \"Sim.\"],\n",
    "         'ct': [\"AS\", \"FS\", \"RM\", \"RL\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37b0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cont_mtx(cat_row, cat_col, cont, num_rows):\n",
    "    cat_rows = np.arange(num_rows)+1\n",
    "    cat_cols = np.arange(num_rows)+1\n",
    "    cont_mtx = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    for idxr, row in np.ndenumerate(cat_rows):\n",
    "        for idxc, col in np.ndenumerate(cat_cols):\n",
    "            cont_mtx[idxr, idxc] = np.nanmean(cont[np.logical_and(cat_row == row,cat_col == col)]);\n",
    "    return cont_mtx;\n",
    "\n",
    "def make_prop_mtx(cat_row, cat_col, numer_var, num_rows):\n",
    "    cat_rows = np.arange(num_rows)+1\n",
    "    cat_cols = np.arange(num_rows)+1\n",
    "    prop_numer = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    prop_denom = np.zeros((cat_rows.size, cat_cols.size))\n",
    "    for idxr, row in np.ndenumerate(cat_rows):\n",
    "        for idxc, col in np.ndenumerate(cat_cols):\n",
    "            subset = np.logical_and(cat_row == row,cat_col == col)\n",
    "            rev_subset = np.logical_and(cat_row == col, cat_col == row)\n",
    "            either_subset = np.logical_or(subset, rev_subset)\n",
    "            prop_numer[idxr, idxc] = np.nansum(numer_var[subset])\n",
    "            prop_denom[idxr, idxc] = np.size(numer_var[subset])\n",
    "            \n",
    "    prop_mtx = np.divide(prop_numer, prop_denom)\n",
    "    return prop_mtx, prop_numer, prop_denom\n",
    "\n",
    "def plot_joint(data, x, y, fig_path, estimator=np.median, text_xpos=.6, text_ypos=.1, marg_color='#b61616', xlim=None, ylim=None, reg_outlier_y=False):\n",
    "    r, p = spearmanr(data[x],data[y])\n",
    "    \n",
    "    reg_x = data[x].to_numpy().reshape(-1, 1)\n",
    "    reg_y = data[y].to_numpy().reshape(-1, 1)\n",
    "    if reg_outlier_y:\n",
    "        y_include = np.logical_and.reduce((data[y]<=(1.5*scipy.stats.iqr(data[y]) + np.quantile(data[y], .75)),\n",
    "                             data[y]>=(-1.5*scipy.stats.iqr(data[y]) + np.quantile(data[y], .25))))\n",
    "        reg_x = reg_x[y_include]\n",
    "        reg_y = reg_y[y_include]\n",
    "        \n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(reg_x, reg_y)\n",
    "    y_pred = regr.predict(reg_x)\n",
    "\n",
    "    b_0 = regr.intercept_\n",
    "    b_1 = regr.coef_[0][0]\n",
    "\n",
    "    g = sns.JointGrid(data=data, x=x, y=y, size=4)\n",
    "    g.plot_joint(sns.regplot,data=data, order=1,x_bins=10,x_estimator=estimator,fit_reg = False, color='k', truncate=True)\n",
    "    \n",
    "    xlim = g.ax_joint.get_xlim()\n",
    "    ylim = g.ax_joint.get_ylim()\n",
    "    sns.kdeplot(y=y, data=data, ax=g.ax_marg_y, fill=False, color=marg_color,  linewidth=2)\n",
    "    sns.kdeplot(x=x, data=data,  ax=g.ax_marg_x, fill=False, color=marg_color, linewidth=2)\n",
    "    \n",
    "    g.ax_joint.get_shared_y_axes().remove(g.ax_joint)\n",
    "    g.ax_joint.get_shared_x_axes().remove(g.ax_joint)\n",
    "    g.ax_joint.set_xlim(xlim)\n",
    "    g.ax_joint.set_ylim(ylim)\n",
    "    \n",
    "    #g.ax_marg_x.set_xticks([g.ax_marg_x.get_xticks()[0],g.ax_marg_x.get_xticks()[-1]])\n",
    "    #g.ax_marg_x.set_xticklabels([str(xlim[0]), str(xlim[1])])\n",
    "    \n",
    "    plt.sca(g.ax_joint)\n",
    "    \n",
    "    plt.plot(reg_x, y_pred, color='k', linewidth=2)\n",
    "\n",
    "    plt_text = '$n =$' + str(int(data.shape[0])) + ',\\n$r_s =$ ' + str(round(r, 2)) + ',\\n' \n",
    "    plt_text = plt_text + '$p_s =$ ' + \"{:.2e}\".format(p) + ',\\n$b_1 =$ ' + \"{:.2e}\".format(b_1)\n",
    "    plt.gca().text(text_xpos,text_ypos,plt_text,transform = plt.gca().transAxes)\n",
    "    set_axis_defaults()\n",
    "    if xlim:\n",
    "        plt.gca().set_xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.gca().set_ylim(ylim)\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def run_linear_regression(data, y, x1, x2):\n",
    "    print('\\033[1m' + 'Linear Regression: ' + y + \" = \" + 'b_0 + ' + 'b_1*' + x1 + ' b_2*' + x2 + ' + interaction \\033[0m')\n",
    "    x1_var = data[x1].to_numpy()\n",
    "    x2_var = data[x2].to_numpy()\n",
    "    x1_x_x2 = x1_var * x2_var\n",
    "    \n",
    "    X = np.stack((x1_var,x2_var, x1_x_x2), axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    y = data[y].to_numpy()\n",
    "    \n",
    "    est = sm.OLS(y, X)\n",
    "    est = est.fit()\n",
    "    print(\"regression p-values:\")\n",
    "    print(est.pvalues)\n",
    "    print(est.summary())\n",
    "\n",
    "def construct_matched_data(data, match_by):\n",
    "    data = data.copy(deep=True)\n",
    "    match_idx = np.argsort(data[match_by].to_numpy())\n",
    "    nobs = match_idx.shape[0]\n",
    "    matched_data = data.head(int(np.floor(nobs/2)))\n",
    "    for column_name, column_data in data.iteritems():\n",
    "        even_data = (column_data.to_numpy()[match_idx])[0:nobs-1:2]\n",
    "        odd_data = (column_data.to_numpy()[match_idx])[1:nobs:2]\n",
    "        matched_data[column_name] = even_data-odd_data\n",
    "        \n",
    "    for column_name, column_data in data.iteritems():\n",
    "        matched_data[column_name + \" matched diff.\"] = matched_data[column_name]\n",
    "    \n",
    "    return matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b487695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis functions\n",
    "def von_mises(x, a_0, a_1, a_2, a_3):\n",
    "    return a_0 + a_1*np.exp(a_2*(np.cos(2*x-2*a_3)-1))\n",
    "\n",
    "def fit_von_mises(ydata):\n",
    "    xdata = np.linspace(0, 2*np.pi, 36)\n",
    "    popt, pcov = scipy.optimize.curve_fit(von_mises, xdata, ydata, maxfev=100000)\n",
    "    return np.rad2deg(xdata), von_mises(xdata,*popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f4b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cad19c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ccg_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-88e5c239d4c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# paper figures/focus on siegle framing/new exclusion criteria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mccg_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ccg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mccg_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccg_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mccg_curr_half\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccg_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ccg_data' is not defined"
     ]
    }
   ],
   "source": [
    "flag = loadmat('output/config.mat')\n",
    "\n",
    "if not flag['group_sessions'][0][0]:\n",
    "    flag['group_labels'] = [\"\"]\n",
    "elif flag['group_by_animals'][0][0]:\n",
    "    flag['group_labels'] = [\"monkey 1\", \"monkey 2\"]\n",
    "else:\n",
    "    flag['group_labels'] = [\"ses 1\", \"ses 2\", \"ses 3\", \"ses 4\", \"ses 5\"]\n",
    "\n",
    "for group_idx in range(int(flag['group_cnt'])):\n",
    "    if flag['group_sessions'][0][0]:\n",
    "        config.figure_dir = \"figures/python/\" + flag['group_labels'][group_idx]+ \"/\"\n",
    "    \n",
    "    #ccg_data = loadmat('output/25-Aug-2021/ccg_attributes_large_' + flag['group_labels'][group_idx] + '.mat', chars_as_strings=True)\n",
    "    #ccg_data = ccg_data['ccg_data'][0][0]\n",
    "\n",
    "    # paper figures/focus on siegle framing/new exclusion criteria\n",
    "    ccg_all = ccg_data['ccg'][0][0].copy()\n",
    "    ccg_curr = ccg_all.copy()\n",
    "    ccg_curr_half = ccg_all.copy()\n",
    "\n",
    "    noise_std = ccg_all['noise_std2']\n",
    "    noise_mean = ccg_all['noise_mean2']\n",
    "    subset = np.logical_and.reduce((noise_std>0, ccg_all['peaks']>7*noise_std + noise_mean, ccg_all['peak_lag']>=-10, ccg_all['peak_lag']<=10));\n",
    "\n",
    "    test = np.transpose((np.arange(subset.shape[0]) % 2) == 0)   \n",
    "    subset_half = np.logical_and(np.squeeze(subset), np.transpose(np.mod(np.arange(subset.shape[0]), 2) == 0))\n",
    "    \n",
    "    # correct depths for both clusters and pairs across sessions\n",
    "    cluster_session = np.squeeze(np.array(ccg_data[0][0]['cluster'][0][0]['Cluster_session'][0][0], dtype='int32'))-1\n",
    "    ses_boundaries = (np.array(config.session_4c56_boundaries))[cluster_session]\n",
    "    ccg_data[0][0]['cluster'][0][0]['Cluster_celldepth'][0][0] = np.squeeze(np.array(ccg_data[0][0]['cluster'][0][0]['Cluster_celldepth'][0][0]))-ses_boundaries\n",
    "\n",
    "    pair_session = np.squeeze(np.array(ccg_data[0][0]['session'][0][0], dtype='int32'))-1\n",
    "    ses_boundaries = (np.array(config.session_4c56_boundaries))[pair_session]\n",
    "    ccg_data[0][0]['pre_depth'][0][0] = np.squeeze(np.array(ccg_data[0][0]['pre_depth'][0][0]))-ses_boundaries\n",
    "    ccg_data[0][0]['post_depth'][0][0] =  np.squeeze(np.array(ccg_data[0][0]['post_depth'][0][0]))-ses_boundaries\n",
    "    \n",
    "    # subset based on signficance\n",
    "    ccg_fields = ccg_data['ccg'][0][0].dtype.names\n",
    "    for field in ccg_fields:\n",
    "        if field != 'config' and field != 'cluster':\n",
    "            ccg_curr[field] = ccg_all[field][np.squeeze(subset)]\n",
    "            ccg_curr_half[field] = ccg_all[field][np.squeeze(subset_half)]\n",
    "\n",
    "    ids = [389, 401, 522, 542]\n",
    "    cols = ['#364958','#55828B','#9E7682','#87BBA2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066accd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure1(ccg_curr,ccg_curr_half, ccg_all, ids):\n",
    "    ids = np.array(ids) + 1 # because 1 indexing for examples\n",
    "    # plot 1 good example ccg (full range)\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[0], ccg_curr['post_id']==ids[1])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    ex_ccg_jitter = ccg_curr['ccg_jitter'][ex_id]\n",
    "    ex_ccg_norm = ccg_curr['ccg_norm'][ex_id]\n",
    "\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_norm), color='#4d5468')\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_jitter), color='#96cad3')\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.fill_between(x=[-100, -50],y1=-0.005, y2=0.005, color=\"#af6a6a\")\n",
    "    plt.legend([\"Uncorrected CCG\", \"Jittered CCG\",\"Corrected CCG\", \"Noise Distribution\"], frameon=False, fontsize=8)\n",
    "    plt.vlines(0,-0.01,0.05, color='k', linestyle='dotted')\n",
    "\n",
    "    plt.fill_between(x=[50, 100],y1=-0.005, y2=0.005, color=\"#af6a6a\")\n",
    "\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.ylim(-0.01, 0.09)\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg.svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # plot dist. of noise_std vs # sig pairs \n",
    "    noise_std_above_mean = np.squeeze((ccg_all['peaks']-ccg_all['noise_mean2'])/ccg_all['noise_std2'])\n",
    "    noise_std_above_mean = noise_std_above_mean[::2] # only select 1 direction of ccgs so that we are not double counting\n",
    "    \n",
    "    total_pairs = noise_std_above_mean.size\n",
    "    pairs_within_10 = np.sum(np.logical_and(np.squeeze(ccg_all['peak_lag'][::2])>=-10, np.squeeze(ccg_all['peak_lag'][::2])<=10))\n",
    "\n",
    "    noise_std_above_mean = noise_std_above_mean[np.logical_and.reduce((~np.isinf(noise_std_above_mean),\n",
    "                                                                      ~np.isnan(noise_std_above_mean), \n",
    "                                                                       np.squeeze(ccg_all['peak_lag'][::2])>=-10, \n",
    "                                                                       np.squeeze(ccg_all['peak_lag'][::2])<=10))]\n",
    "\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    ecdf_calc = []\n",
    "    for i in np.arange(7,20.1,.1):\n",
    "            ecdf_calc.append(np.sum(noise_std_above_mean>i))\n",
    "            \n",
    "    sns.ecdfplot(x=noise_std_above_mean, stat='count', complementary=True, color='k')\n",
    "    plt.xlim(0, 20)\n",
    "    plt.ylabel(\"number of pairs\")\n",
    "    plt.xlabel(\"peak > x std. above noise\")\n",
    "    plt.axvline(7, color='k', linestyle='solid')\n",
    "    plt.gca().text(10, 20000,'all, n = ' + str(int(total_pairs)) + '\\n'+\n",
    "                   '|lag|<=10, n = ' + str(int(pairs_within_10)) + '\\n'+\n",
    "                   'sig., n = ' + str(int(np.sum(noise_std_above_mean>7))))\n",
    "    plt.fill_between(np.arange(7,20.1,.1), ecdf_calc,color='#b8e0d2' )\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_sig_cdf.svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_figure1_ex_ccgs(ccg_curr, ids, cols):\n",
    "    ids = np.array(ids) + 1 # because 1 indexing for examples\n",
    "    # plot 1 good example ccg (full range)\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[0], ccg_curr['post_id']==ids[1])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.axvline(0, color='k', linestyle='dotted')\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    plt.gca().text(10, .015,'lag = ' + str(-int(ccg_curr['peak_lag'][ex_id])) + \" ms \\npeak = \"+ str(rounded_peak))\n",
    "    plt.gca().text(-55, .008,'neuron 3\\nleads', horizontalAlignment='center', color=cols[0], size=10)\n",
    "    plt.gca().text(60, .008,'neuron 4\\nleads', horizontalAlignment='center', color=cols[1], size=10)\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg_sim.svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[2], ccg_curr['post_id']==ids[3])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.axvline(0, color='k', linestyle='dotted')\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    plt.gca().text(10, .015,'lag = ' + str(-int(ccg_curr['peak_lag'][ex_id])) + \" ms \\npeak = \"+ str(rounded_peak))\n",
    "    plt.gca().text(-55, .008,'neuron 1\\nleads', horizontalAlignment='center', color=cols[2], size=10)\n",
    "    plt.gca().text(60, .008,'neuron 2\\nleads', horizontalAlignment='center', color=cols[3], size=10)\n",
    "\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg_dif.svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_figure1_ex_ccgs(ccg_curr, ids, cols)\n",
    "plot_figure1(ccg_curr,ccg_curr_half, ccg_all, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure2(ccg_curr_half, config):\n",
    "    data = pd.DataFrame({\"med. peak\": np.squeeze((ccg_curr_half['peaks'])),\n",
    "                  \"avg. |time lag| (ms)\": np.squeeze(np.abs(ccg_curr_half['peak_lag'])),\n",
    "                  \"vert. pair distance ($\\mu$m)\": np.squeeze(ccg_curr_half['pair_distance']),\n",
    "                  \"$r_{ori}$\": np.squeeze(ccg_curr_half['r_ori']), \"put. cell type\": np.squeeze(ccg_curr_half['pre_sc'])})\n",
    "\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_pd.svg'\n",
    "    plot_joint(data, x, y, fig_path, estimator=np.mean,xlim=(0,1100))\n",
    "\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_ori.svg'\n",
    "    plot_joint(data, x, y, fig_path, text_ypos =.7,estimator=np.mean,xlim=(-.3,1))\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_pd.svg'\n",
    "    plot_joint(data, x, y, fig_path, text_ypos =.7, estimator=np.median,xlim=(0,1100), reg_outlier_y=True)\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_ori.svg'\n",
    "    plot_joint(data, x, y, fig_path, text_xpos=.1,text_ypos =.7, estimator=np.median, reg_outlier_y=True)\n",
    "\n",
    "    y = \"$r_{ori}$\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_ori_vs_pd.svg'\n",
    "    plot_joint(data, x, y, fig_path=fig_path, estimator=np.mean,text_ypos =.7,xlim=(0,1100))\n",
    "\n",
    "    y = \"vert. pair distance ($\\mu$m)\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_pd_vs_ori.svg'\n",
    "    plot_joint(data, x, y, fig_path=fig_path, estimator=np.mean,text_ypos =.7,)\n",
    "\n",
    "    dist_matched_data = construct_matched_data(data, 'vert. pair distance ($\\mu$m)')\n",
    "    r_ori_matched_data = construct_matched_data(data, '$r_{ori}$')\n",
    "\n",
    "    xs = [\"vert. pair distance ($\\mu$m) matched diff.\", \"vert. pair distance ($\\mu$m) matched diff.\", \"$r_{ori}$ matched diff.\", \"$r_{ori}$ matched diff.\"]\n",
    "    ys = [\"med. peak matched diff.\", \"avg. |time lag| (ms) matched diff.\",\"med. peak matched diff.\", \"avg. |time lag| (ms) matched diff.\"]\n",
    "    reg_outlier_y = [True, False, True, False]\n",
    "    datasets = [r_ori_matched_data, r_ori_matched_data, dist_matched_data, dist_matched_data]\n",
    "    fig_paths = [\"fig2_ori_matched_peak\",\"fig2_ori_matched_lag\",\"fig2_dist_matched_peak\",\"fig2_dist_matched_lag\"]\n",
    "    text_y_pos = [.7, .1, .1, .7]\n",
    "    estimators = [np.median, np.mean, np.median, np.mean]\n",
    "\n",
    "    for x, y, tdata, estimator, outlier, y_pos, f_path in zip(xs, ys, datasets, estimators, reg_outlier_y, text_y_pos, fig_paths):\n",
    "        fig_path=config.figure_dir + f_path  + '.svg'\n",
    "        plot_joint(tdata, x, y, fig_path=fig_path, estimator=estimator, text_ypos = y_pos, reg_outlier_y=outlier)\n",
    "\n",
    "    run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\")\n",
    "    run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\")\n",
    "\n",
    "plot_figure2(ccg_curr_half, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19c185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_figure2_ex_tune(ccg_curr, ccg_all, ids, cols):\n",
    "    sim1_col = cols[0]\n",
    "    sim2_col = cols[1]\n",
    "    dif1_col = cols[2]\n",
    "    dif2_col = cols[3]\n",
    "    sim_idx1 = ids[0]\n",
    "    sim_idx2 = ids[1]\n",
    "    dif_idx1 = ids[2]\n",
    "    dif_idx2 = ids[3]\n",
    "\n",
    "    ori_tuning = np.squeeze(ccg_curr['cluster'][0][0]['mean_ori_tune'])\n",
    "    ses_3_tuning = ori_tuning\n",
    "    ses_3_tuning = np.transpose(np.transpose(ses_3_tuning) - np.ndarray.min(ses_3_tuning, axis=1)) # subtract min, new min = 0\n",
    "    one_over_range = 1/np.ptp(ses_3_tuning, axis=1)\n",
    "    ses_3_tuning = ses_3_tuning*one_over_range[:,np.newaxis]     \n",
    "\n",
    "\n",
    "\n",
    "    ori_tune_cell1 = ses_3_tuning[sim_idx1]\n",
    "    ori_tune_cell2 = ses_3_tuning[sim_idx2]\n",
    "\n",
    "    ori1_x, ori1_y = fit_von_mises(ori_tune_cell1)\n",
    "    ori2_x, ori2_y = fit_von_mises(ori_tune_cell2)\n",
    "\n",
    "    theta =  np.arange(0, 1+1/36, 1/36)*2*np.pi\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'},figsize=(1,2))\n",
    "    ax.plot(theta, np.append(ori1_y, ori1_y[0]), linewidth=2, color=sim1_col)\n",
    "    ax.plot(theta, np.append(ori2_y, ori2_y[0]), linewidth=2, color=sim2_col)\n",
    "    ax.set_thetagrids([0,90,180,270])\n",
    "    ax.set_rticks([])  # Less radial ticks\n",
    "    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line\n",
    "    ax.grid(True)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_aspect(2)\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_tune_sim.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ori_tune_cell1 = ses_3_tuning[dif_idx1]\n",
    "    ori_tune_cell2 = ses_3_tuning[dif_idx2]\n",
    "\n",
    "    ori1_x, ori1_y = fit_von_mises(ori_tune_cell1)\n",
    "    ori2_x, ori2_y = fit_von_mises(ori_tune_cell2)\n",
    "\n",
    "    theta =  np.arange(0, 1+1/36, 1/36)*2*np.pi\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'},figsize=(1,2))\n",
    "    ax.plot(theta, np.append(ori1_y, ori1_y[0]), linewidth=2, color=dif1_col)\n",
    "    ax.plot(theta, np.append(ori2_y, ori2_y[0]), linewidth=2, color=dif2_col)\n",
    "    ax.set_thetagrids([0,90,180,270])\n",
    "    ax.set_rticks([])  # Less radial ticks\n",
    "    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line\n",
    "    ax.grid(True)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_aspect(2)\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_tune_diff.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(2.5,2.5))\n",
    "\n",
    "    df = pd.DataFrame({'firing rate cell 3': ses_3_tuning[sim_idx1], 'firing rate cell 4': ses_3_tuning[sim_idx2]})\n",
    "    sns.scatterplot(data=df, x='firing rate cell 3', y='firing rate cell 4', color='k')\n",
    "    plt.gca().text(.5, .4, '$r_{ori}$=' + str(round(float(ccg_all['r_ori'][np.logical_and(ccg_all['pre_id']==sim_idx1+1, ccg_all['post_id']==sim_idx2+1)]),2)), fontsize=10)\n",
    "\n",
    "    plt.xlabel(plt.gca().get_xlabel(), color=sim1_col) #, bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    plt.ylabel(plt.gca().get_ylabel(), color=sim2_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_signal_corr_sim.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "    plt.figure(figsize=(2.5,2.5))\n",
    "    df = pd.DataFrame({'firing rate cell 1': ses_3_tuning[dif_idx1], 'firing rate cell 2': ses_3_tuning[dif_idx2]})    \n",
    "    sns.scatterplot(data=df, x='firing rate cell 1', y='firing rate cell 2', color='k')\n",
    "    plt.text(.5, .8, '$r_{ori}$=' + str(round(float(ccg_all['r_ori'][np.logical_and(ccg_all['pre_id']==dif_idx1+1, ccg_all['post_id']==dif_idx2+1)]),2)), fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.xlabel(plt.gca().get_xlabel(), color=dif1_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    plt.ylabel(plt.gca().get_ylabel(), color=dif2_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_signal_corr_diff.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()    \n",
    "    \n",
    "def plot_figure2_network(ccg_curr_half, ids, cols):\n",
    "    ccg_curr_half_t = ccg_curr_half.copy()\n",
    "    session_idx = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_session'])\n",
    "    depths = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celldepth'])\n",
    "    med_peaks = []\n",
    "    for idx in range(ccg_curr_half_t['cluster'][0][0]['Cluster_session'].size):\n",
    "        med_peaks.append(np.median(ccg_curr_half_t['peaks'][np.logical_or(ccg_curr_half_t['pre_id'] == idx+1,ccg_curr_half_t['post_id'] == idx+1)]))\n",
    "\n",
    "    cell_layer = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celllayer'])\n",
    "    mean_peaks = np.array(med_peaks)\n",
    "    ccg_curr = ccg_curr_half_t\n",
    "    \n",
    "    plt.figure(figsize=(4,6))\n",
    "    np.random.default_rng(0)\n",
    "    xrand = np.random.randn(*depths.shape)\n",
    "    pre_x = np.ones_like(depths)+xrand/2\n",
    "    cell_layer = np.array([(labels['cl'][int(layer)-1] if ~np.isnan(layer) else np.nan) for layer in cell_layer])\n",
    "    uq_ses = np.unique(session_idx)\n",
    "    xdiv = 5\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    \n",
    "    nfive_quant = np.nanquantile(mean_peaks, .95)\n",
    "    mean_peaks[mean_peaks>nfive_quant] = nfive_quant\n",
    "    \n",
    "    xs = np.array([])\n",
    "    ys = np.array([])\n",
    "    \n",
    "    for i in range(uq_ses.size):\n",
    "        ses_id = np.squeeze((session_idx == uq_ses[i]))\n",
    "        xs = np.concatenate((xs, pre_x[ses_id] + xdiv*i))\n",
    "        ys = np.concatenate((ys, depths[ses_id]))\n",
    "    \n",
    "    idx = np.argsort(depths)\n",
    "    sns.scatterplot(x = xs, y = ys, hue=mean_peaks)\n",
    "    #plt.plot(mean_peaks[idx]/np.nanmax(mean_peaks[idx]), depths[idx])\n",
    "    plt.legend(frameon=False, loc='lower right')\n",
    "    for i in range(uq_ses.size):\n",
    "        ses_id = session_idx == uq_ses[i]\n",
    "        xticks.append(xdiv*i+1)\n",
    "        xticklabels.append('ses.' + str(i+1))\n",
    "\n",
    "        if i == 2:\n",
    "            for j in range(len(cols)):\n",
    "                plt.scatter(pre_x[ids[j]] + xdiv*i, depths[ids[j]], color=cols[j],s=80)\n",
    "            plt.plot([pre_x[ids[0]] + xdiv*i, pre_x[ids[1]] + xdiv*i],[depths[ids[0]],depths[ids[1]]], linewidth=2, color='k')\n",
    "            plt.plot([pre_x[ids[2]] + xdiv*i, pre_x[ids[3]] + xdiv*i],[depths[ids[2]],depths[ids[3]]], linewidth=2, color='k')\n",
    "            plt.plot([xdiv*i+4,xdiv*i+4],[depths[ids[0]],depths[ids[1]]], linestyle='--',linewidth=2, color='k')\n",
    "            plt.plot([xdiv*i+4,xdiv*i+4],[depths[ids[2]],depths[ids[3]]], linestyle='--',linewidth=2, color='k')\n",
    "            plt.text(xdiv*i+4.5,(depths[ids[2]]+depths[ids[3]])/2, 'p.d.=' + str(round(abs(depths[ids[2]]-depths[ids[3]])))+\" $\\mu m$\")\n",
    "            plt.text(xdiv*i+4.5,(depths[ids[0]]+depths[ids[1]])/2, 'p.d.=' + str(round(abs(depths[ids[0]]-depths[ids[1]])))+\" $\\mu m$\")\n",
    "    plt.gca().set_xlim(plt.gca().get_xlim()[0], plt.gca().get_xlim()[1]*1.4)\n",
    "    ###plt.gca().legend(np.flip(np.append(labels['cl'], '_Hidden')), loc='upper right', frameon=False) \n",
    "    set_axis_defaults()\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().set_xticklabels(xticklabels)\n",
    "    plt.gca().set_xticks(xticks)\n",
    "    plt.ylabel(\"cortical depth ($\\mu m$)\")\n",
    "    plt.savefig(config.figure_dir + 'fig2_network.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_figure2_network_one_ses_no_peaks(ccg_curr_half, ids, cols):\n",
    "    ccg_curr_half_t = ccg_curr_half.copy()\n",
    "    session_idx = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_session'])\n",
    "    depths = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celldepth'])\n",
    "    med_peaks = []\n",
    "    for idx in range(ccg_curr_half_t['cluster'][0][0]['Cluster_session'].size):\n",
    "        med_peaks.append(np.median(ccg_curr_half_t['peaks'][np.logical_or(ccg_curr_half_t['pre_id'] == idx+1,ccg_curr_half_t['post_id'] == idx+1)]))\n",
    "\n",
    "    cell_layer = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celllayer'])\n",
    "    mean_peaks = np.array(med_peaks)\n",
    "    ccg_curr = ccg_curr_half_t\n",
    "    \n",
    "    plt.figure(figsize=(4,6))\n",
    "    np.random.default_rng(0)\n",
    "    xrand = np.random.randn(*depths.shape)\n",
    "    pre_x = np.ones_like(depths)+xrand/2\n",
    "    cell_layer = np.array([(labels['cl'][int(layer)-1] if ~np.isnan(layer) else np.nan) for layer in cell_layer])\n",
    "    uq_ses = np.unique(session_idx)\n",
    "    xdiv = 5\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    \n",
    "    nfive_quant = np.nanquantile(mean_peaks, .95)\n",
    "    mean_peaks[mean_peaks>nfive_quant] = nfive_quant\n",
    "    \n",
    "    xs = np.array([])\n",
    "    ys = np.array([])\n",
    "    \n",
    "    for i in range(uq_ses.size):\n",
    "        if i == 2:\n",
    "            ses_id = np.squeeze((session_idx == uq_ses[i]))\n",
    "            xs = np.concatenate((xs, pre_x[ses_id]+xdiv*i))\n",
    "            ys = np.concatenate((ys, depths[ses_id]))\n",
    "    \n",
    "    idx = np.argsort(depths)\n",
    "    sns.scatterplot(x = xs, y = ys, color='k')\n",
    "    #plt.plot(mean_peaks[idx]/np.nanmax(mean_peaks[idx]), depths[idx])\n",
    "    #plt.legend(frameon=False, loc='lower right')\n",
    "    for i in range(uq_ses.size):\n",
    "        ses_id = session_idx == uq_ses[i]\n",
    "        if i == 2:\n",
    "            xticks.append(xdiv*i+1)\n",
    "            xticklabels.append('session 3')\n",
    "\n",
    "            if i == 2:\n",
    "                for j in range(len(cols)):\n",
    "                    plt.scatter(pre_x[ids[j]] + xdiv*i, depths[ids[j]], color=cols[j],s=80)\n",
    "                plt.plot([pre_x[ids[0]] + xdiv*i, pre_x[ids[1]] + xdiv*i],[depths[ids[0]],depths[ids[1]]], linewidth=2, color='k')\n",
    "                plt.plot([pre_x[ids[2]] + xdiv*i, pre_x[ids[3]] + xdiv*i],[depths[ids[2]],depths[ids[3]]], linewidth=2, color='k')\n",
    "                plt.plot([xdiv*i+2.75,xdiv*i+2.75],[depths[ids[0]],depths[ids[1]]], linestyle='--',linewidth=2, color='k')\n",
    "                plt.plot([xdiv*i+2.75,xdiv*i+2.75],[depths[ids[2]],depths[ids[3]]], linestyle='--',linewidth=2, color='k')\n",
    "                plt.text(xdiv*i+3,(depths[ids[2]]+depths[ids[3]])/2, 'p.d.=' + str(round(abs(depths[ids[2]]-depths[ids[3]])))+\" $\\mu m$\")\n",
    "                plt.text(xdiv*i+3,(depths[ids[0]]+depths[ids[1]])/2, 'p.d.=' + str(round(abs(depths[ids[0]]-depths[ids[1]])))+\" $\\mu m$\")\n",
    "    plt.gca().set_xlim(plt.gca().get_xlim()[0], plt.gca().get_xlim()[1]*1.3)\n",
    "    ###plt.gca().legend(np.flip(np.append(labels['cl'], '_Hidden')), loc='upper right', frameon=False) \n",
    "    set_axis_defaults()\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().set_xticklabels(xticklabels)\n",
    "    plt.gca().set_xticks(xticks)\n",
    "    plt.ylabel(\"cortical depth ($\\mu m$)\")\n",
    "    plt.savefig(config.figure_dir + 'fig2_network.svg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_figure2_ex_tune(ccg_curr, ccg_all, ids, cols)\n",
    "#plot_figure2_network(ccg_curr_half, ids, cols)\n",
    "plot_figure2_network_one_ses_no_peaks(ccg_curr_half, ids, cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858e390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67398b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6fd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487cf91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
