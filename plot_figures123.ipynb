{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c8d3bf",
   "metadata": {},
   "source": [
    "# Functional connections among neurons withing single columns of Macaque V1\n",
    "This notebook generates the plots for figures 1, 2 and 3 and supplemental figures 1-4 of the manuscript, *Functional connections among neurons withing single columns of Macaque V1*. This notebook plots the relationship between CCG peak and lag and cortical distance and tuning similarity and demonstrates the methods used to compute these metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1cd6bf",
   "metadata": {},
   "source": [
    "### Section 1: Setup constants and helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c9e4c",
   "metadata": {},
   "source": [
    "First, we import the necessary dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521545f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import spearmanr, linregress\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat\n",
    "from sklearn import linear_model\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "# set plot output format\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('pdf')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# initialize a random seed for replicating model fits\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe9293",
   "metadata": {},
   "source": [
    "Next, we define `config` and `labels` that holds constants for the project including the figure directory, the boundaries between layers 4c and 5/6 in each session, and names for different layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config to hold constants\n",
    "class structtype():\n",
    "    pass\n",
    "\n",
    "config = structtype()\n",
    "config.figure_dir = \"figures/python/\"\n",
    "config.session_4c56_boundaries = [1070, 1190,990,750,550]\n",
    "def set_axis_defaults():\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "# define categorical variable labels\n",
    "labels = {'cl': [\"2/3\", \"4a/b\", \"4cα\", \"4cβ\", \"5\", \"6\", \"WM\"], \n",
    "         'sc': [\"Com.\", \"Sim.\"],\n",
    "         'ct': [\"AS\", \"FS\", \"RM\", \"RL\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5971c75",
   "metadata": {},
   "source": [
    "Finally, we define a variety of helper functions for analyses and plotting. These functions include plotting the relationship between two continuous variables (`plot_joint`), running various linear regressions (`run_linear_regression`), constructing distance-matched pairs (`construct_matched_data`), and a variety of analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_joint(data, x, y, fig_path, estimator=np.median, text_xpos=.6, text_ypos=.1, marg_color='#b61616', xlim=None, ylim=None, reg_outlier_y=False, order=1, is_peak=False, is_peak_match=False):\n",
    "    r, p = spearmanr(data[x],data[y])\n",
    "    \n",
    "    reg_x = data[x].to_numpy().reshape(-1, 1)\n",
    "    reg_y = data[y].to_numpy().reshape(-1, 1)\n",
    "    if reg_outlier_y:\n",
    "        y_include = np.logical_and.reduce((data[y]<=(1.5*scipy.stats.iqr(data[y]) + np.quantile(data[y], .75)),\n",
    "                             data[y]>=(-1.5*scipy.stats.iqr(data[y]) + np.quantile(data[y], .25))))\n",
    "        reg_x = reg_x[y_include]\n",
    "        reg_y = reg_y[y_include]\n",
    "    \n",
    "    if order == 'exp':\n",
    "        lamb, popt, y_pred = fit_exponential(reg_x, reg_y)\n",
    "        reg_x = np.linspace(np.quantile(np.squeeze(reg_x),.1), np.quantile(np.squeeze(reg_x),.9),1000)\n",
    "        y_pred = exponential(reg_x, *popt)\n",
    "        print(popt)\n",
    "    else:\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(reg_x, reg_y)\n",
    "        \n",
    "        reg_x = reg_x[reg_x[:, 0].argsort()]\n",
    "        y_pred = regr.predict(reg_x)\n",
    "        \n",
    "\n",
    "        b_0 = regr.intercept_\n",
    "        b_1 = regr.coef_[0][0]\n",
    "        reg_x = reg_x[:,0]\n",
    "    \n",
    "    g = sns.JointGrid(data=data, x=x, y=y, size=4)\n",
    "    g.plot_joint(sns.regplot,data=data,x_bins=10,x_estimator=estimator,fit_reg = False, color='k', truncate=True)\n",
    "    \n",
    "    xlim = g.ax_joint.get_xlim()\n",
    "    ylim = g.ax_joint.get_ylim()\n",
    "    sns.kdeplot(y=y, data=data, ax=g.ax_marg_y, fill=False, color=marg_color,  linewidth=2)\n",
    "    sns.kdeplot(x=x, data=data,  ax=g.ax_marg_x, fill=False, color=marg_color, linewidth=2)\n",
    "    \n",
    "    g.ax_joint.get_shared_y_axes().remove(g.ax_joint)\n",
    "    g.ax_joint.get_shared_x_axes().remove(g.ax_joint)\n",
    "    g.ax_joint.set_xlim(xlim)\n",
    "    g.ax_joint.set_ylim(ylim)\n",
    "    \n",
    "    if is_peak:\n",
    "        g.ax_marg_y.set_ylim([0,0.075])\n",
    "    if is_peak_match:\n",
    "        g.ax_marg_y.set_ylim([-0.05, 0.05])\n",
    "    \n",
    "    plt.sca(g.ax_joint)\n",
    "    plt.plot(reg_x, y_pred, color='k', linewidth=2)\n",
    "\n",
    "    plt_text = '$n =$' + str(int(data.shape[0])) + ',\\n$r_s =$ ' + str(round(r, 2)) + ',\\n' \n",
    "    if order == 1:\n",
    "        plt_text = plt_text + '$p_s =$ ' + \"{:.2e}\".format(p) + ',\\n$b_1 =$ ' + \"{:.2e}\".format(b_1)\n",
    "    elif order == 'exp':\n",
    "        plt_text = plt_text + '$p_s =$ ' + \"{:.2e}\".format(p) + ',\\n$\\lambda =$ ' + \"{:.2e}\".format(lamb)\n",
    "    plt.gca().text(text_xpos,text_ypos,plt_text,transform = plt.gca().transAxes)\n",
    "    set_axis_defaults()\n",
    "    if xlim:\n",
    "        plt.gca().set_xlim(xlim)\n",
    "    if ylim:\n",
    "        plt.gca().set_ylim(ylim)\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def run_linear_regression(data, y, x1, x2, exclude_outliers = False, include_interaction=True, include_x2=True, standardize=False):\n",
    "    print('\\033[1m' + 'Linear Regression: ' + y + \" = \" + 'b_0 + ' + 'b_1*' + x1 + ' b_2*' + x2 + ' + interaction \\033[0m')\n",
    "\n",
    "    x1_var = data[x1].to_numpy()\n",
    "    if include_x2:\n",
    "        x2_var = data[x2].to_numpy()\n",
    "        \n",
    "    y = data[y].to_numpy()\n",
    "    if exclude_outliers:\n",
    "        y_include = np.logical_and.reduce((y<=(1.5*scipy.stats.iqr(y) + np.quantile(y, .75)),\n",
    "                             y>=(-1.5*scipy.stats.iqr(y) + np.quantile(y, .25))))\n",
    "        y = y[y_include]\n",
    "        x1_var = x1_var[y_include]\n",
    "        if include_x2:\n",
    "            x2_var = x2_var[y_include]\n",
    "\n",
    "    if include_x2 and include_interaction:\n",
    "        x1_x_x2 = x1_var * x2_var\n",
    "    \n",
    "    if standardize:\n",
    "        x1_var = (x1_var-np.mean(x1_var))/np.std(x1_var)\n",
    "        if include_x2:\n",
    "            x2_var =  (x2_var-np.mean(x2_var))/np.std(x2_var)\n",
    "        if include_interaction:\n",
    "            x1_x_x2 = (x1_x_x2-np.mean(x1_x_x2))/np.std(x1_x_x2)\n",
    "    \n",
    "    if include_x2 and include_interaction:\n",
    "        X = np.stack((x1_var,x2_var, x1_x_x2), axis=1)\n",
    "    elif include_x2:\n",
    "        X = np.stack((x1_var,x2_var), axis=1)\n",
    "    else:\n",
    "        X = x1_var\n",
    "        \n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    \n",
    "    est = sm.OLS(y, X)\n",
    "    est = est.fit()\n",
    "    print(\"regression p-values:\")\n",
    "    print(est.pvalues)\n",
    "    print(est.summary())\n",
    "\n",
    "def construct_matched_data(data, match_by):\n",
    "    data = data.copy(deep=True)\n",
    "    match_idx = np.argsort(data[match_by].to_numpy())\n",
    "    nobs = match_idx.shape[0]\n",
    "    matched_data = data.head(int(np.floor(nobs/2)))\n",
    "    for column_name, column_data in data.iteritems():\n",
    "        even_data = (column_data.to_numpy()[match_idx])[0:nobs-1:2]\n",
    "        odd_data = (column_data.to_numpy()[match_idx])[1:nobs:2]\n",
    "        matched_data[column_name] = even_data-odd_data\n",
    "        \n",
    "    for column_name, column_data in data.iteritems():\n",
    "        matched_data[column_name + \" diff.\"] = matched_data[column_name]\n",
    "    \n",
    "    return matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b487695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis functions\n",
    "def von_mises(x, a_0, a_1, a_2, a_3):\n",
    "    return a_0 + a_1*np.exp(a_2*(np.cos(2*x-2*a_3)-1))\n",
    "\n",
    "def fit_von_mises(ydata):\n",
    "    xdata = np.linspace(0, 2*np.pi, 36)\n",
    "    print(xdata.shape)\n",
    "    print(ydata.shape)\n",
    "    popt, pcov = scipy.optimize.curve_fit(von_mises, xdata, ydata, maxfev=100000)\n",
    "    return np.rad2deg(xdata), von_mises(xdata,*popt)\n",
    "\n",
    "def exponential(x, y_0,y_1, lamb):\n",
    "    return y_0*np.exp(x*-lamb) +y_1\n",
    "\n",
    "def cost_function(params,x,y):\n",
    "    return np.sum(np.abs(y - exponential(x, *params)))\n",
    "\n",
    "def fit_exp_linear(t, y, C=0):\n",
    "    y = y - C\n",
    "    y = np.log(y)\n",
    "    K, A_log = np.polyfit(t, y, 1)\n",
    "    A = np.exp(A_log)\n",
    "    return A, K\n",
    "\n",
    "def fit_exponential(x, y):\n",
    "    popt, pcov = scipy.optimize.curve_fit(exponential, x.squeeze(), y.squeeze(), bounds=([0,0,0],[0.1,.1,0.1]),maxfev=10000)\n",
    "    res = scipy.optimize.minimize(cost_function, popt, args=(x.squeeze(), y.squeeze()),bounds=([(0,0.1),(0,.1),(0,0.1)]))\n",
    "    print(res.x)\n",
    "    return res.x[2],res.x, exponential(x,*res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e2dcb",
   "metadata": {},
   "source": [
    "### Section 2: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = loadmat('output/config.mat')\n",
    "\n",
    "if not flag['group_sessions'][0][0]:\n",
    "    flag['group_labels'] = [\"\"]\n",
    "elif flag['group_by_animals'][0][0]:\n",
    "    flag['group_labels'] = [\"monkey 1\", \"monkey 2\"]\n",
    "else:\n",
    "    flag['group_labels'] = [\"ses 1\", \"ses 2\", \"ses 3\", \"ses 4\", \"ses 5\"]\n",
    "\n",
    "for group_idx in range(int(flag['group_cnt'])):\n",
    "    if flag['group_sessions'][0][0]:\n",
    "        config.figure_dir = \"figures/python/\" + flag['group_labels'][group_idx]+ \"/\"\n",
    "    \n",
    "    ccg_data = loadmat('output/25-Aug-2021/ccg_attributes_large_' + flag['group_labels'][group_idx] + '.mat', chars_as_strings=True)\n",
    "    ccg_data = ccg_data['ccg_data'][0][0]\n",
    "\n",
    "    # paper figures/focus on siegle framing/new exclusion criteria\n",
    "    ccg_all = ccg_data['ccg'][0][0].copy()\n",
    "    ccg_curr = ccg_all.copy()\n",
    "    ccg_curr_half = ccg_all.copy()\n",
    "\n",
    "    noise_distribution2 = np.concatenate((ccg_all['ccg_control'][:,:50],ccg_all['ccg_control'][:,150:]), axis=1)\n",
    "    print(noise_distribution2.shape)\n",
    "    noise_distribution2[1::2,:] = noise_distribution2[0:-1:2,:]\n",
    "\n",
    "    ccg_all['noise_std2'] = np.expand_dims(np.nanstd(noise_distribution2,axis=1,ddof=1),axis=1);\n",
    "    ccg_all['noise_mean2'] = np.expand_dims(np.nanmean(noise_distribution2,axis=1),axis=1);\n",
    "\n",
    "    noise_std = ccg_all['noise_std2']\n",
    "    noise_mean = ccg_all['noise_mean2']\n",
    "    \n",
    "    subset = np.logical_and.reduce((noise_std>0, ccg_all['peaks']>(7*noise_std + noise_mean), ccg_all['peak_lag']>=-10, ccg_all['peak_lag']<=10));\n",
    "\n",
    "    test = np.transpose((np.arange(subset.shape[0]) % 2) == 0)   \n",
    "    subset_half = np.logical_and(np.squeeze(subset), np.transpose(np.mod(np.arange(subset.shape[0]), 2) == 0))\n",
    "    \n",
    "    # correct depths for both clusters and pairs across sessions\n",
    "    cluster_session = np.squeeze(np.array(ccg_data[0][0]['cluster'][0][0]['Cluster_session'][0][0], dtype='int32'))-1\n",
    "    ses_boundaries = (np.array(config.session_4c56_boundaries))[cluster_session]\n",
    "    ccg_data[0][0]['cluster'][0][0]['Cluster_celldepth'][0][0] = np.squeeze(np.array(ccg_data[0][0]['cluster'][0][0]['Cluster_celldepth'][0][0]))-ses_boundaries\n",
    "\n",
    "    pair_session = np.squeeze(np.array(ccg_data[0][0]['session'][0][0], dtype='int32'))-1\n",
    "    ses_boundaries = (np.array(config.session_4c56_boundaries))[pair_session]\n",
    "    ccg_data[0][0]['pre_depth'][0][0] = np.squeeze(np.array(ccg_data[0][0]['pre_depth'][0][0]))-ses_boundaries\n",
    "    ccg_data[0][0]['post_depth'][0][0] =  np.squeeze(np.array(ccg_data[0][0]['post_depth'][0][0]))-ses_boundaries\n",
    "    \n",
    "    # subset based on signficance\n",
    "    ccg_fields = ccg_data['ccg'][0][0].dtype.names\n",
    "    for field in ccg_fields:\n",
    "        if field != 'config' and field != 'cluster':\n",
    "            ccg_curr[field] = ccg_all[field][np.squeeze(subset)]\n",
    "            ccg_curr_half[field] = ccg_all[field][np.squeeze(subset_half)]\n",
    "    ids = np.array([385, 389, 397, 500])-1\n",
    "    ids_orig = [389, 401, 522, 542]\n",
    "    old_cols = ['#FF0F80','#E9190F','#008BF8','#F5B700']\n",
    "    cols = ['#f5aa9b', '#e72124','#f4b61a','#4482c4']\n",
    "    \n",
    "    #plot_figure2(ccg_curr_half, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ba80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data summary \n",
    "for i in range(1,6):\n",
    "    num_ses = np.sum(ccg_curr_half['session'] == i)\n",
    "    print(f'# sig. pairs, session {i}: {num_ses}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a418517f",
   "metadata": {},
   "source": [
    "### Section 3: Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c383c9",
   "metadata": {},
   "source": [
    "#### Plot Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066accd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([390, 402, 355, 389])-1\n",
    "#ids = np.array([462, 449, 527, 500])-1\n",
    "ids = np.array([450, 465, 527, 500])-1\n",
    "set_matplotlib_formats('pdf')\n",
    "\n",
    "def plot_figure1(ccg_curr,ccg_curr_half, ccg_all, ids):\n",
    "    ids = np.array(ids) + 1 # because 1 indexing for examples\n",
    "    # plot 1 good example ccg (full range)\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[0], ccg_curr['post_id']==ids[1])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    ex_ccg_jitter = ccg_curr['ccg_jitter'][ex_id]\n",
    "    ex_ccg_norm = ccg_curr['ccg_norm'][ex_id]\n",
    "\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_norm), color='#A1A1A1')\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_jitter), color='#96cad3')\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.fill_between(x=[-100, -50],y1=-0.005, y2=0.005, color=\"#af6a6a\")\n",
    "    plt.legend([\"Uncorrected CCG\", \"Jittered CCG\",\"Corrected CCG\", \"Noise Distribution\"], frameon=False, fontsize=8)\n",
    "    plt.vlines(0,-0.01,0.05, color='k', linestyle='dotted')\n",
    "\n",
    "    plt.fill_between(x=[50, 100],y1=-0.005, y2=0.005, color=\"#af6a6a\")\n",
    "\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.ylim(-0.01, 0.09)\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # plot dist. of noise_std vs # sig pairs \n",
    "    noise_std_above_mean = np.squeeze((ccg_all['peaks']-ccg_all['noise_mean2'])/ccg_all['noise_std2'])\n",
    "    noise_std_above_mean = noise_std_above_mean[::2] # only select 1 direction of ccgs so that we are not double counting\n",
    "    \n",
    "    total_pairs = noise_std_above_mean.size\n",
    "    pairs_within_10 = np.sum(np.logical_and(np.squeeze(ccg_all['peak_lag'][::2])>=-10, np.squeeze(ccg_all['peak_lag'][::2])<=10))\n",
    "\n",
    "    noise_std_above_mean = noise_std_above_mean[np.logical_and.reduce((~np.isinf(noise_std_above_mean),\n",
    "                                                                      ~np.isnan(noise_std_above_mean), \n",
    "                                                                       np.squeeze(ccg_all['peak_lag'][::2])>=-10, \n",
    "                                                                       np.squeeze(ccg_all['peak_lag'][::2])<=10))]\n",
    "\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    ecdf_calc = []\n",
    "    for i in np.arange(7,20.1,.1):\n",
    "            ecdf_calc.append(np.sum(noise_std_above_mean>i))\n",
    "            \n",
    "    sns.ecdfplot(x=noise_std_above_mean, stat='count', complementary=True, color='k')\n",
    "    plt.xlim(0, 20)\n",
    "    plt.ylabel(\"number of pairs\")\n",
    "    plt.xlabel(\"peak > x std. above noise\")\n",
    "    plt.axvline(7, color='k', linestyle='solid')\n",
    "    plt.gca().text(10, 20000,'all, n = ' + str(int(total_pairs)) + '\\n'+\n",
    "                   '|lag|<=10, n = ' + str(int(pairs_within_10)) + '\\n'+\n",
    "                   'sig., n = ' + str(int(np.sum(noise_std_above_mean>7))))\n",
    "    plt.fill_between(np.arange(7,20.1,.1), ecdf_calc,color='#96cad3')\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_sig_cdf.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_figure1_inhib_ccgs(ccg_curr,ccg_curr_half, ccg_all, ids):\n",
    "    # plot dist. of noise_std vs # sig inhib pairs \n",
    "    noise_std_below_mean = np.squeeze((ccg_all['troughs']-ccg_all['noise_mean2'])/ccg_all['noise_std2'])\n",
    "    noise_std_below_mean = noise_std_below_mean[::2] # only select 1 direction of ccgs so that we are not double counting\n",
    "    \n",
    "    total_pairs = noise_std_below_mean.size\n",
    "    pairs_within_10 = np.sum(np.logical_and(np.squeeze(ccg_all['trough_lag'][::2])>=-10, np.squeeze(ccg_all['trough_lag'][::2])<=10))\n",
    "\n",
    "    noise_std_below_mean = noise_std_below_mean[np.logical_and.reduce((~np.isinf(noise_std_below_mean),\n",
    "                                                                      ~np.isnan(noise_std_below_mean), \n",
    "                                                                       np.squeeze(ccg_all['trough_lag'][::2])>=-10, \n",
    "                                                                       np.squeeze(ccg_all['trough_lag'][::2])<=10))]\n",
    "\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    ecdf_calc = []\n",
    "    for i in np.arange(-10,-7,.1):\n",
    "            ecdf_calc.append(np.sum(noise_std_below_mean<i))\n",
    "            \n",
    "    sns.ecdfplot(x=noise_std_below_mean, stat='count', complementary=True, color='k')\n",
    "    plt.xlim(-10,0)\n",
    "    plt.ylabel(\"number of pairs\")\n",
    "    plt.xlabel(\"trough < x std. below noise\")\n",
    "    plt.axvline(-7, color='k', linestyle='solid')\n",
    "    plt.gca().text(-10, 20000,'all, n = ' + str(int(total_pairs)) + '\\n'+\n",
    "                   '|lag|<=10, n = ' + str(int(pairs_within_10)) + '\\n'+\n",
    "                   'sig., n = ' + str(int(np.sum(noise_std_below_mean<-7))))\n",
    "    plt.fill_between(np.arange(-10,-7.1,.1), ecdf_calc,color='#96cad3')\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_sig_inhib_cdf.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_figure1_ex_ccgs(ccg_curr, ids, cols):\n",
    "    ids = np.array(ids) + 1 # because 1 indexing for examples\n",
    "    # plot 1 good example ccg (full range)\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[0], ccg_curr['post_id']==ids[1])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.axvline(0, color='k', linestyle='dotted')\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    plt.gca().text(10, .015,'lag = ' + str(-int(ccg_curr['peak_lag'][ex_id])) + \" ms \\npeak = \"+ str(rounded_peak))\n",
    "    #plt.gca().text(-55, .008,'neuron 3\\nleads', horizontalAlignment='center', color=cols[0], size=10)\n",
    "    #plt.gca().text(60, .008,'neuron 4\\nleads', horizontalAlignment='center', color=cols[1], size=10)\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg_sim.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    ex_id = np.nonzero(np.squeeze(np.logical_and(ccg_curr['pre_id']==ids[2], ccg_curr['post_id']==ids[3])))\n",
    "    ex_ccg_control = ccg_curr['ccg_control'][ex_id]\n",
    "    plt.figure(figsize=(2,2.66))\n",
    "    plt.plot(np.arange(-100,101), np.squeeze(ex_ccg_control), color='k',)\n",
    "    plt.axvline(0, color='k', linestyle='dotted')\n",
    "    plt.xlim((-100, 100))\n",
    "    plt.xlabel('time lag (ms)')\n",
    "    plt.ylabel('efficacy (coincidences/spike)')\n",
    "\n",
    "    rounded_peak =  round(float(ccg_curr['peaks'][ex_id]), 2 - int(np.floor(np.log10(abs(ccg_curr['peaks'][ex_id])))) - 1)\n",
    "    plt.gca().text(10, .015,'lag = ' + str(-int(ccg_curr['peak_lag'][ex_id])) + \" ms \\npeak = \"+ str(rounded_peak))\n",
    "    #plt.gca().text(-55, .008,'neuron 1\\nleads', horizontalAlignment='center', color=cols[2], size=10)\n",
    "    #plt.gca().text(60, .008,'neuron 2\\nleads', horizontalAlignment='center', color=cols[3], size=10)\n",
    "\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig1_ex_ccg_dif.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_figure1_ex_ccgs(ccg_curr, ids, cols)\n",
    "plot_figure1(ccg_curr,ccg_curr_half, ccg_all, ids_orig)\n",
    "plot_figure1_inhib_ccgs(ccg_curr,ccg_curr_half, ccg_all, ids_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04669d5c",
   "metadata": {},
   "source": [
    "#### Plot Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats('pdf')\n",
    "\n",
    "def plot_figure2(ccg_curr_half, config):\n",
    "    data = pd.DataFrame({\"med. peak\": np.squeeze((ccg_curr_half['peaks'])),\n",
    "                  \"avg. |time lag| (ms)\": np.squeeze(np.abs(ccg_curr_half['peak_lag'])),\n",
    "                  \"vert. pair distance ($\\mu$m)\": np.squeeze(ccg_curr_half['pair_distance']),\n",
    "                  \"$r_{ori}$\": np.squeeze(ccg_curr_half['r_ori']), \"put. cell type\": np.squeeze(ccg_curr_half['pre_sc'])})\n",
    "\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_pd.pdf'\n",
    "    plot_joint(data, x, y, fig_path, estimator=np.mean,xlim=(0,1100))\n",
    "\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_ori.pdf'\n",
    "    plot_joint(data, x, y, fig_path, text_ypos =.7,estimator=np.mean,xlim=(-.3,1))\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_pd.pdf'\n",
    "    plot_joint(data, x, y, fig_path, text_ypos =.7, estimator=np.median,xlim=(0,1100), reg_outlier_y=True, order='exp', is_peak=True)\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_ori.pdf'\n",
    "    plot_joint(data, x, y, fig_path, text_xpos=.1,text_ypos =.7, estimator=np.median, reg_outlier_y=True, is_peak=True)\n",
    "\n",
    "    y = \"$r_{ori}$\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_ori_vs_pd.pdf'\n",
    "    plot_joint(data, x, y, fig_path=fig_path, estimator=np.mean,text_ypos =.7,xlim=(0,1100))\n",
    "\n",
    "    y = \"vert. pair distance ($\\mu$m)\"\n",
    "    x = \"$r_{ori}$\"\n",
    "    fig_path = config.figure_dir + 'fig2_pd_vs_ori.pdf'\n",
    "    plot_joint(data, x, y, fig_path=fig_path, estimator=np.mean,text_ypos =.7,)\n",
    "\n",
    "    dist_matched_data = construct_matched_data(data, 'vert. pair distance ($\\mu$m)')\n",
    "    r_ori_matched_data = construct_matched_data(data, '$r_{ori}$')\n",
    "\n",
    "    xs = [\"vert. pair distance ($\\mu$m) diff.\", \"vert. pair distance ($\\mu$m) diff.\", \"$r_{ori}$ diff.\", \"$r_{ori}$ diff.\"]\n",
    "    ys = [\"med. peak diff.\", \"avg. |time lag| (ms) diff.\",\"med. peak diff.\", \"avg. |time lag| (ms) diff.\"]\n",
    "    reg_outlier_y = [True, False, True, False]\n",
    "    datasets = [r_ori_matched_data, r_ori_matched_data, dist_matched_data, dist_matched_data]\n",
    "    fig_paths = [\"fig2_ori_matched_peak\",\"fig2_ori_matched_lag\",\"fig2_dist_matched_peak\",\"fig2_dist_matched_lag\"]\n",
    "    text_y_pos = [.7, .1, .1, .7]\n",
    "    estimators = [np.median, np.mean, np.median, np.mean]\n",
    "\n",
    "    for x, y, tdata, estimator, outlier, y_pos, f_path in zip(xs, ys, datasets, estimators, reg_outlier_y, text_y_pos, fig_paths):\n",
    "        fig_path=config.figure_dir + f_path  + '.pdf'\n",
    "        plot_joint(tdata, x, y, fig_path=fig_path, estimator=estimator, text_ypos = y_pos, reg_outlier_y=outlier, is_peak_match=outlier)\n",
    "        \n",
    "    run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\")\n",
    "    run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", exclude_outliers=True)\n",
    "\n",
    "def run_figure2_ancovas(ccg_curr_half, config):\n",
    "    pd = np.squeeze(ccg_curr_half['pair_distance'])\n",
    "    peak = np.squeeze((ccg_curr_half['peaks']))\n",
    "    lag = np.squeeze(np.abs(ccg_curr_half['peak_lag']))\n",
    "    within = np.squeeze(ccg_curr_half['pre_cl'] == ccg_curr_half['post_cl'])\n",
    "    ancova(y=peak, cont_x=pd, cat_x=within, label=\"peak vs within, pd as cov\", cat_labs=[\"within\", \"between\"])\n",
    "    ancova(y=lag, cont_x=pd, cat_x=within, label=\"lag vs within, pd as cov\", cat_labs=[\"within\", \"between\"])\n",
    "    pass\n",
    "\n",
    "def ancova(y, cont_x, cat_x, label,cat_labs, exclude_outliers=True):\n",
    "    if exclude_outliers:\n",
    "        y_include = np.logical_and.reduce((y<=(1.5*scipy.stats.iqr(y) + np.quantile(y, .75)),\n",
    "                             y>=(-1.5*scipy.stats.iqr(y) + np.quantile(y, .25))))\n",
    "        x_include = np.logical_and.reduce((cont_x<=(1.5*scipy.stats.iqr(cont_x) + np.quantile(cont_x, .75)),\n",
    "                             y>=(-1.5*scipy.stats.iqr(cont_x) + np.quantile(cont_x, .25))))\n",
    "        include = np.logical_and(y_include, x_include)\n",
    "        y = y[include]\n",
    "        cont_x = cont_x[include]\n",
    "        cat_x = cat_x[include]\n",
    "        \n",
    "    lr_result = linregress(x=cont_x, y=y)\n",
    "    pred_y = lr_result.slope*cont_x + lr_result.intercept\n",
    "    residuals = y - pred_y\n",
    "\n",
    "        \n",
    "    F,p = stats.f_oneway(residuals[cat_x], residuals[~cat_x])\n",
    "    print(f'{label}(1,{np.size(y)-1}) ancova f={F}, p={p}')\n",
    "    print(f'\\t{cat_labs[0]} mean - {cat_labs[1]} mean: {np.mean(residuals[cat_x])-np.mean(residuals[~cat_x])}')\n",
    "    \n",
    "\n",
    "plot_figure2(ccg_curr_half, config)\n",
    "run_figure2_ancovas(ccg_curr_half, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d90412",
   "metadata": {},
   "source": [
    "#### Fit related linear regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"med. peak\": np.squeeze((ccg_curr_half['peaks'])),\n",
    "              \"avg. |time lag| (ms)\": np.squeeze(np.abs(ccg_curr_half['peak_lag'])),\n",
    "              \"vert. pair distance ($\\mu$m)\": np.squeeze(ccg_curr_half['pair_distance']),\n",
    "              \"$r_{ori}$\": np.squeeze(ccg_curr_half['r_ori']), \"put. cell type\": np.squeeze(ccg_curr_half['pre_sc'])})\n",
    "\n",
    "print(\"========================No standardization========================\")\n",
    "run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\")\n",
    "run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", exclude_outliers=True)\n",
    "\n",
    "print(\"\\n\\n========================No Interaction========================\")\n",
    "run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", include_interaction=False)\n",
    "run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", exclude_outliers=True, include_interaction=False)\n",
    "\n",
    "print(\"\\n\\n========================Only pd========================\")\n",
    "run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"none\", include_interaction=False, include_x2=False)\n",
    "run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"none\", exclude_outliers=True, include_interaction=False, include_x2=False)\n",
    "\n",
    "print(\"\\n\\n========================Only ori========================\")\n",
    "run_linear_regression(data, \"avg. |time lag| (ms)\",  \"$r_{ori}$\",\"none\", include_interaction=False, include_x2=False)\n",
    "run_linear_regression(data, \"med. peak\",  \"$r_{ori}$\", \"none\", exclude_outliers=True, include_interaction=False, include_x2=False)\n",
    "\n",
    "print(\"\\n\\n========================Standardized No Interaction=====================\")\n",
    "run_linear_regression(data, \"avg. |time lag| (ms)\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", include_interaction=False, standardize=True)\n",
    "run_linear_regression(data, \"med. peak\", \"vert. pair distance ($\\mu$m)\", \"$r_{ori}$\", exclude_outliers=True, include_interaction=False, standardize=True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3719a7f",
   "metadata": {},
   "source": [
    "#### Plot example distances and tuning curves for figure 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19c185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_figure2_ex_tune(ccg_curr, ccg_all, ids, cols):\n",
    "    sim1_col = cols[0]\n",
    "    sim2_col = cols[1]\n",
    "    dif1_col = cols[2]\n",
    "    dif2_col = cols[3]\n",
    "    sim_idx1 = ids[0]\n",
    "    sim_idx2 = ids[1]\n",
    "    dif_idx1 = ids[2]\n",
    "    dif_idx2 = ids[3]\n",
    "\n",
    "    ori_tuning = np.squeeze(ccg_curr['cluster'][0][0]['mean_ori_tune'])\n",
    "    ses_3_tuning = ori_tuning\n",
    "    #ses_3_tuning = np.transpose(np.transpose(ses_3_tuning) - np.ndarray.min(ses_3_tuning, axis=1)) # subtract min, new min = 0\n",
    "    #one_over_range = 1/np.ptp(ses_3_tuning, axis=1)\n",
    "    #ses_3_tuning = ses_3_tuning*one_over_range[:,np.newaxis]     \n",
    "\n",
    "\n",
    "\n",
    "    ori_tune_cell1 = ses_3_tuning[sim_idx1]\n",
    "    ori_tune_cell2 = ses_3_tuning[sim_idx2]\n",
    "\n",
    "    ori1_x, ori1_y = fit_von_mises(ori_tune_cell1)\n",
    "    ori2_x, ori2_y = fit_von_mises(ori_tune_cell2)\n",
    "\n",
    "    theta =  np.arange(0, 1+1/36, 1/36)*2*np.pi\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'},figsize=(1,2))\n",
    "    ax.plot(theta, np.append(ori1_y, ori1_y[0]), linewidth=2, color=sim1_col)\n",
    "    ax.plot(theta, np.append(ori2_y, ori2_y[0]), linewidth=2, color=sim2_col)\n",
    "    ax.set_thetagrids([0,90,180,270])\n",
    "    ax.set_rticks([])  # Less radial ticks\n",
    "    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line\n",
    "    ax.grid(True)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_aspect(2)\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_tune_sim.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ori_tune_cell1 = ses_3_tuning[dif_idx1]\n",
    "    ori_tune_cell2 = ses_3_tuning[dif_idx2]\n",
    "\n",
    "    ori1_x, ori1_y = fit_von_mises(ori_tune_cell1)\n",
    "    ori2_x, ori2_y = fit_von_mises(ori_tune_cell2)\n",
    "\n",
    "    theta =  np.arange(0, 1+1/36, 1/36)*2*np.pi\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'},figsize=(1,2))\n",
    "    ax.plot(theta, np.append(ori1_y, ori1_y[0]), linewidth=2, color=dif1_col)\n",
    "    ax.plot(theta, np.append(ori2_y, ori2_y[0]), linewidth=2, color=dif2_col)\n",
    "    ax.set_thetagrids([0,90,180,270])\n",
    "    ax.set_rticks([])  # Less radial ticks\n",
    "    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line\n",
    "    ax.grid(True)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "    ax.set_aspect(2)\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_tune_diff.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "\n",
    "    df = pd.DataFrame({'firing rate cell 3': ses_3_tuning[sim_idx1], 'firing rate cell 4': ses_3_tuning[sim_idx2]})\n",
    "    plt.scatter(df['firing rate cell 3'].to_numpy(), df['firing rate cell 4'].to_numpy(), color='k')\n",
    "    plt.gca().text(.5, .4, '$r_{ori}$=' + str(round(float(ccg_all['r_ori'][np.logical_and(ccg_all['pre_id']==sim_idx1+1, ccg_all['post_id']==sim_idx2+1)]),2)), fontsize=10)\n",
    "    \n",
    "    plt.xlabel('firing rate neuron 3', color=sim1_col) #, bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    plt.ylabel('firing rate neuron 4', color=sim2_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_signal_corr_sim.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "    plt.figure(figsize=(2,2))\n",
    "    df = pd.DataFrame({'firing rate cell 1': ses_3_tuning[dif_idx1], 'firing rate cell 2': ses_3_tuning[dif_idx2]})    \n",
    "    plt.scatter(df['firing rate cell 1'].to_numpy(), df['firing rate cell 2'].to_numpy(), color='k')\n",
    "    plt.text(.5, .8, '$r_{ori}$=' + str(round(float(ccg_all['r_ori'][np.logical_and(ccg_all['pre_id']==dif_idx1+1, ccg_all['post_id']==dif_idx2+1)]),2)), fontsize=10)\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    plt.xlabel('firing rate neuron 1', color=dif1_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    plt.ylabel('firing rate neuron 2', color=dif2_col) #,  bbox={'boxstyle': 'round', 'color':'k'}\n",
    "    set_axis_defaults()\n",
    "    plt.savefig(config.figure_dir + 'fig2_ex_signal_corr_diff.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()    \n",
    "    \n",
    "def plot_figure2_network(ccg_curr_half, ids, cols):\n",
    "    ccg_curr_half_t = ccg_curr_half.copy()\n",
    "    session_idx = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_session'])\n",
    "    depths = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celldepth'])\n",
    "    med_peaks = []\n",
    "    for idx in range(ccg_curr_half_t['cluster'][0][0]['Cluster_session'].size):\n",
    "        med_peaks.append(np.median(ccg_curr_half_t['peaks'][np.logical_or(ccg_curr_half_t['pre_id'] == idx+1,ccg_curr_half_t['post_id'] == idx+1)]))\n",
    "\n",
    "    cell_layer = np.squeeze(ccg_curr_half_t['cluster'][0][0]['Cluster_celllayer'])\n",
    "    mean_peaks = np.array(med_peaks)\n",
    "    ccg_curr = ccg_curr_half_t\n",
    "    \n",
    "    plt.figure(figsize=(4,6))\n",
    "    np.random.default_rng(0)\n",
    "    xrand = np.random.randn(*depths.shape)\n",
    "    pre_x = np.ones_like(depths)+xrand/2\n",
    "    cell_layer = np.array([(labels['cl'][int(layer)-1] if ~np.isnan(layer) else np.nan) for layer in cell_layer])\n",
    "    uq_ses = np.unique(session_idx)\n",
    "    xdiv = 5\n",
    "    xticks = []\n",
    "    xticklabels = []\n",
    "    \n",
    "    nfive_quant = np.nanquantile(mean_peaks, .95)\n",
    "    mean_peaks[mean_peaks>nfive_quant] = nfive_quant\n",
    "    \n",
    "    xs = np.array([])\n",
    "    ys = np.array([])\n",
    "    \n",
    "    for i in range(uq_ses.size):\n",
    "        if i == 2:\n",
    "            ses_id = np.squeeze((session_idx == uq_ses[i]))\n",
    "            xs = np.concatenate((xs, pre_x[ses_id]+xdiv*i))\n",
    "            ys = np.concatenate((ys, depths[ses_id]))\n",
    "    \n",
    "    idx = np.argsort(depths)\n",
    "    plt.scatter(x = xs, y = ys, color='k')\n",
    "    #plt.plot(mean_peaks[idx]/np.nanmax(mean_peaks[idx]), depths[idx])\n",
    "    #plt.legend(frameon=False, loc='lower right')\n",
    "    for i in range(uq_ses.size):\n",
    "        ses_id = session_idx == uq_ses[i]\n",
    "        if i == 2:\n",
    "            xticks.append(xdiv*i+1)\n",
    "            xticklabels.append('session 3')\n",
    "\n",
    "            if i == 2:\n",
    "                for j in range(len(cols)):\n",
    "                    plt.scatter(pre_x[ids[j]] + xdiv*i, depths[ids[j]], color=cols[j],s=80)\n",
    "                plt.plot([pre_x[ids[0]] + xdiv*i, pre_x[ids[1]] + xdiv*i],[depths[ids[0]],depths[ids[1]]], linewidth=2, color='k')\n",
    "                plt.plot([pre_x[ids[2]] + xdiv*i, pre_x[ids[3]] + xdiv*i],[depths[ids[2]],depths[ids[3]]], linewidth=2, color='k')\n",
    "                plt.plot([xdiv*i+2.75,xdiv*i+2.75],[depths[ids[0]],depths[ids[1]]], linestyle='--',linewidth=2, color='k')\n",
    "                plt.plot([xdiv*i+2.75,xdiv*i+2.75],[depths[ids[2]],depths[ids[3]]], linestyle='--',linewidth=2, color='k')\n",
    "                plt.text(xdiv*i+3,(depths[ids[2]]+depths[ids[3]])/2, 'p.d.=' + str(round(abs(depths[ids[2]]-depths[ids[3]])))+\" $\\mu m$\")\n",
    "                plt.text(xdiv*i+3,(depths[ids[0]]+depths[ids[1]])/2, 'p.d.=' + str(round(abs(depths[ids[0]]-depths[ids[1]])))+\" $\\mu m$\")\n",
    "    plt.gca().set_xlim(plt.gca().get_xlim()[0], plt.gca().get_xlim()[1]*1.3)\n",
    "    ###plt.gca().legend(np.flip(np.append(labels['cl'], '_Hidden')), loc='upper right', frameon=False) \n",
    "    set_axis_defaults()\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().set_xticklabels(xticklabels)\n",
    "    plt.gca().set_xticks(xticks)\n",
    "    plt.ylabel(\"cortical depth ($\\mu m$)\")\n",
    "    plt.savefig(config.figure_dir + 'fig2_network.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_figure2_ex_tune(ccg_curr, ccg_all, ids, cols)\n",
    "plot_figure2_network(ccg_curr_half, ids, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee6a1b",
   "metadata": {},
   "source": [
    "#### Plot supplemental figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats('pdf')\n",
    "\n",
    "def plot_supplementk(data):\n",
    "    ## within vs between distance vs peak and lag\n",
    "\n",
    "    within = data['pre layer'] == data['post layer']\n",
    "    \n",
    "    data_within = data.loc[within]\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_pd_within.pdf'\n",
    "    plot_joint(data_within, x, y, fig_path, estimator=np.mean,xlim=(0,1100))\n",
    "    \n",
    "    data_between = data.loc[np.logical_not(within)]\n",
    "    y = \"avg. |time lag| (ms)\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_lag_vs_pd_between.pdf'\n",
    "    plot_joint(data_between, x, y, fig_path, estimator=np.mean,xlim=(0,1100))\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_within.pdf'\n",
    "    plot_joint(data_within, x, y, fig_path, text_ypos =.7, estimator=np.median,xlim=(0,1100), reg_outlier_y=True, order='exp', is_peak=True)\n",
    "\n",
    "    y = \"med. peak\"\n",
    "    x = \"vert. pair distance ($\\mu$m)\"\n",
    "    fig_path = config.figure_dir + 'fig2_peak_vs_between.pdf'\n",
    "    plot_joint(data_between, x, y, fig_path, text_ypos =.7, estimator=np.median,xlim=(0,1100), reg_outlier_y=True, order='exp', is_peak=True)\n",
    "\n",
    "    ## specific layer combinations correlations\n",
    "    uq_layers = np.unique(data[\"pre layer\"])\n",
    "    peak_dist_corr = np.zeros((uq_layers.size, uq_layers.size))\n",
    "    lag_dist_corr = np.zeros((uq_layers.size, uq_layers.size))\n",
    "    \n",
    "    df_arr = []\n",
    "    peak_arr = []\n",
    "    for id1 in range(len(uq_layers)):\n",
    "        for id2 in range(id1, len(uq_layers)):\n",
    "            pre_post = np.logical_and(data[\"pre layer\"] == uq_layers[id1],data[\"post layer\"]==uq_layers[id2])\n",
    "            post_pre = np.logical_and(data[\"pre layer\"] == uq_layers[id2],data[\"post layer\"]==uq_layers[id1])\n",
    "            pair_subset = np.logical_or(pre_post, post_pre)\n",
    "            \n",
    "            lag_dist_corr[id1, id2], plag = spearmanr(data[\"vert. pair distance ($\\mu$m)\"].loc[pair_subset], data[\"avg. |time lag| (ms)\"].loc[pair_subset])\n",
    "            peak_dist_corr[id1, id2], ppeak = spearmanr(data[\"vert. pair distance ($\\mu$m)\"].loc[pair_subset], data[\"med. peak\"].loc[pair_subset])\n",
    "            \n",
    "            pre_layer = labels['cl'][id1]\n",
    "            post_layer = labels['cl'][id2]\n",
    "            if plag<1e-4:\n",
    "                df_arr.append([pre_layer, post_layer, lag_dist_corr[id1, id2]])\n",
    "            else:\n",
    "                df_arr.append([pre_layer, post_layer, 0])\n",
    "            if ppeak<1e-4:\n",
    "                peak_arr.append([pre_layer, post_layer, peak_dist_corr[id1, id2]])\n",
    "            else:\n",
    "                peak_arr.append([pre_layer, post_layer, 0])\n",
    "\n",
    "    sns.set(color_codes=True, font_scale=1.2)\n",
    "    \n",
    "\n",
    "data = pd.DataFrame({\"med. peak\": np.squeeze((ccg_curr_half['peaks'])),\n",
    "              \"avg. |time lag| (ms)\": np.squeeze(np.abs(ccg_curr_half['peak_lag'])),\n",
    "              \"vert. pair distance ($\\mu$m)\": np.squeeze(ccg_curr_half['pair_distance']),\n",
    "              \"$r_{ori}$\": np.squeeze(ccg_curr_half['r_ori']), \n",
    "                \"pre layer\": np.squeeze(ccg_curr_half['pre_cl']), \n",
    "                \"post layer\": np.squeeze(ccg_curr_half['post_cl'])})\n",
    "\n",
    "df = plot_supplementk(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e55657",
   "metadata": {},
   "source": [
    "#### List distance matching statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"med. peak\": np.squeeze((ccg_curr_half['peaks'])),\n",
    "              \"avg. |time lag| (ms)\": np.squeeze(np.abs(ccg_curr_half['peak_lag'])),\n",
    "              \"vert. pair distance ($\\mu$m)\": np.squeeze(ccg_curr_half['pair_distance']),\n",
    "              \"$r_{ori}$\": np.squeeze(ccg_curr_half['r_ori']), \"put. cell type\": np.squeeze(ccg_curr_half['pre_sc'])})\n",
    "\n",
    "dist_matched_data = construct_matched_data(data, 'vert. pair distance ($\\mu$m)')\n",
    "r_ori_matched_data = construct_matched_data(data, '$r_{ori}$')\n",
    "\n",
    "dist_matched_data['vert. pair distance ($\\mu$m) diff. abs'] = abs(dist_matched_data['vert. pair distance ($\\mu$m) diff.'])\n",
    "dist_matched_data.head(10)\n",
    "dmd = pd.DataFrame(dist_matched_data['vert. pair distance ($\\mu$m) diff. abs'])\n",
    "dmd.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86990cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd = dmd.sort_values(by='vert. pair distance ($\\mu$m) diff. abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 46\n",
    "print(f'{100*p/5122} percent of data')\n",
    "dmd.tail(p)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
